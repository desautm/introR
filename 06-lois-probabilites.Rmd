# Les lois de probabilités

Pour être en mesure d'utiliser les lois de probabilités en langage `R`, il faut charger le paquetage `stats`.

```{r}
library(stats)
library(ggplot2)
```

Chaque distribution en `R` possède quatre fonctions qui lui sont associées. Premièrement, la fonction possède un _nom racine_, par exemple le _nom racine_ pour la distribution *binomiale* est `binom`. Cette racine est précédée par une de ces quatre lettre:

- `p` pour *probabilité*, qui représente la fonction de répartition
- `q` pour *quantile*, l'inverse de la fonction de répartition
- `d` pour *densité*, la fonction de densité de la distribution
- `r` pour *random*, une variable aléatoire suivant la distribution spécifiée.

Pour la loi binomiale par exemple, ces fonctions sont `pbinom`, `qbinom`, `dbinom` et `rbinom`.

## Les lois de probabilités discrètes

### La loi binomiale

Le _nom racine_ pour la loi binomiale est `binom`.

Soit $X$: le nombre de succès en $n$ essais et $X\sim B(n,p)$. Voici la façon de calculer des probabilités pour la loi binomiale à l'aide de `R`:

|Probabilités|Commande `R`|
|-----------:|:-----------|
|$P(X=k)$    |`dbinom(k, n, p)`|
|$P(i\leq X \leq j)$ | `sum(dbinom(i:j, n, p))`|
|$P(X\leq k)$ | `pbinom(k, n, p)` |
|$P(X>k)$ | `1-pbinom(k, n, p)` |

Soit $X$ la variable aléatoire comptant le nombre de face 2 que nous obtenons en lançant un dé à quatre reprises. Nous avons que $X\sim B(4,\frac{1}{6})$. Si nous voulons calculer $P(X=3)$, nous aurons:

```{r}
dbinom(3,4,1/6)
```

Nous avons donc une probabilité de `r dbinom(3,4,1/6)*100`% d'obtenir 3 fois la face deux en lançant un dé à quatres reprises.

Nous pouvons représenter graphiquement la loi binomiale. Soit $X~B(10,1/4)$. Nous aurons:

```{r}
fbinom <- data.frame(x = 0:10, y = dbinom(0:10, 10, 1/4))
ggplot(fbinom, aes(x = x, y = y)) +
  geom_bar(width = 0.1, stat = "identity") +
  labs(
    x = "Nombre de succès",
    y = "Probabilité",
    title = "Répartition de la probabilité de la loi binomiale en fonction du nombre de succès"
  )
```

### La loi de Poisson

Le _nom racine_ pour la loi de Poisson est `pois`.

Soit $X$: le nombre d'événements dans un intervalle fixé et $X\sim Po(\lambda)$. Voici la façon de calculer des probabilités pour la loi de Poisson à l'aide de `R`:

|Probabilités|Commande `R`|
|-----------:|:-----------|
|$P(X=k)$    |`dpois(k, lambda)`|
|$P(i\leq X \leq j)$ | `sum(dpois(i:j, lambda))`|
|$P(X\leq k)$ | `ppois(k, lambda)` |
|$P(X>k)$ | `1-ppois(k, lambda)` |

Soit $X$ le nombre d'erreurs dans une page. Si une page contient en moyenne une demie erreur alors $X\sim Po(1/2)$. Si nous voulons calculer $P(X=2)$, nous aurons:

```{r}
dpois(2, 1/2)
```

Nous avons donc une probabilité de `r dpois(2, 1/2)*100`% d'obtenir deux erreurs sur une page.

Nous pouvons représenter graphiquement la loi de Poisson. Soit $X~Po(1/2)$. Nous aurons:

```{r}
fpois <- data.frame(x = 0:10, y = dpois(0:10, 1/2))
ggplot(fpois, aes(x = x, y = y)) +
  geom_bar(width = 0.1, stat = "identity") +
  labs(
    x = "Nombre d'événements",
    y = "Probabilité",
    title = "Répartition de la probabilité de la loi de Poisson en fonction du nombre d'événements"
  )
```

### La loi géométrique

Le _nom racine_ pour la loi géométrique est `geom`.

Soit $X$: le nombre d'échecs avant d'obtenir un succès et $X\sim G(p)$. Voici la façon de calculer des probabilités pour la loi géométrique à l'aide de `R`:

|Probabilités|Commande `R`|
|-----------:|:-----------|
|$P(X=k)$    |`dgeom(k, p)`|
|$P(i\leq X \leq j)$ | `sum(dgeom(i:j, p))`|
|$P(X\leq k)$ | `pgeom(k, p)` |
|$P(X>k)$ | `1-pgeom(k, p)` |

Soit $X$ le nombre d'échecs avant d'avoir un premier succès. Si la probabilité de succès est $\frac{1}{5}$ alors $X\sim G(1/5)$. Si nous voulons calculer $P(X=6)$, nous aurons:

```{r}
dgeom(6, 1/5)
```

Nous avons donc une probabilité de `r dgeom(6, 1/5)*100`% d'obtenir 6 échecs avant un premier succès.

Nous pouvons représenter graphiquement la loi géométrique. Soit $X\sim G(1/5)$. Nous aurons:

```{r}
fgeom <- data.frame(x = 0:10, y = dgeom(0:10, 1/5))
ggplot(fgeom, aes(x = x, y = y)) +
  geom_bar(width = 0.1, stat = "identity") +
  labs(
    x = "Nombre d'événements",
    y = "Probabilité",
    title = "Répartition de la probabilité de la loi géométrique en fonction du nombre d'échecs avant le premier succès"
  )
```

> Remarque : Pour la loi géométrique, on rencontre parfois cette définition : la probabilité p'(k) est la probabilité, lors d'une succession d'épreuves de Bernoulli indépendantes, d'obtenir k échecs avant un succès. On remarque qu'il ne s'agit que d'un décalage de la précédente loi géométrique. Si $X$ suit la loi $p$, alors $X+1$ suit la loi $p'$.

### La loi hypergéométrique

Le _nom racine_ pour la loi hypergéométrique est `hyper`.

On tire sans remise $n$ objets d'un ensemble de $N$ objets dont $A$
possèdent une caractéristique particulière (et les autres $B=N-A$ ne la possèdent pas). Soit $X$ le nombre d'objets de l'échantillon qui possèdent la caractéristique. Nous avons que $X\sim H(N,A,n)$.

Voici la façon de calculer des probabilités pour la loi hypergéométrique à l'aide de `R`:

|Probabilités|Commande `R`|
|-----------:|:-----------|
|$P(X=k)$    |`dhyper(k, A, B, n)`|
|$P(i\leq X \leq j)$ | `sum(dhyper(i:j, A, B, n))`|
|$P(X\leq k)$ | `phyper(k, A, B, n)` |
|$P(X>k)$ | `1-phyper(k, A, B, n)` |

Soit $X$ le nombre de boules blanches de l'échantillon de taille 4. Si l'urne contient 5 boules blanches et 8 boules noires, nous avons $X\sim H(13,5,4)$. Si nous voulons calculer $P(X=2)$, nous aurons:

```{r}
dhyper(2, 5, 8, 4)
```

Nous avons donc une probabilité de `r dhyper(2, 5, 8, 4)*100`% de piger 2 boules blanches dans un échantillon de taille 4.

## Les lois de probabilités continues
